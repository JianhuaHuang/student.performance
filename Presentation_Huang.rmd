---
title: 'Student Performance Prediction and Key Factors Identification'
author: "Jianhua Huang"
date: "October 24, 2016"
output: 
  slidy_presentation:
    fig_width: 7
    fig_height: 5
    duration: 50
    incremental: true
runtime: shiny
---

```{r knitr.setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, cache = FALSE)
```

## Introduction 
<ul class = "incremental">
**Data Source**

Secondary school student attributes and performance: publicaly available https://archive.ics.uci.edu/ml/datasets/Student+Performance 

```{r, echo=FALSE}
var <- read.csv('data/variable.explanation.csv')
colnames(var) <- gsub('X', '', colnames(var))
var
```

**Research Questions**

1. Is it possible to predict student performance before a class begins?
2. What are the important factors driving the performance differences among students?
</ul>

## Data Preparation
<ul class = "incremental">
**Load R Packages**
```{r,results='hide'}
# Load pacakges
sapply(c('caret', 'e1071', 'knitr', 'reshape2', 'rpart', 'scales', 'gridExtra', 
  'glmnet', 'doSNOW', 'dplyr', 'ggplot2', 'streamlineR'), 
  require, character.only = TRUE, quietly = TRUE)
```

**Load Data**
```{r}
dt.org <- read.csv('data/student.grade.csv')
dt <- select(dt.org, -famincome)
dt$grade <- as.factor(dt$grade)

head(dt, 3)  # top 3 rows
str(dt)  # data structure
```

**Exclude Variables Without Variation**
```{r}
nzv(dt, saveMetrics = TRUE)  ## near zero variation
```

**Bin Numerical Variables Based on Univariate Regression: `bin.knn`**

1. Divide the numerical variable x into small buckets with approximate equal frequences.
2. Build a univariate model using x and y
3. Get the regression coefficients for all buckets
4. Use the KNN algorithm to bin the neighbouring buckets into bigger groups

```{r,eval=FALSE}
bin.knn(grade ~ famincome, data = dt.org, n.group = 5, min.bucket = 0.05)
```


```{r,echo=FALSE}
# shiny app use the variable globally
# since famincome is removed in dt later, it can't be used here.
# Thus the dt.org should be used
inputPanel(
  sliderInput("n_group", label = 'Number of Groups',
              min = 1, max = 9, value = 5, step = 1, ticks = FALSE),
  sliderInput("min_pop", label = 'Minimum Bucket',
              min = 0.01, max = .2, value = .06, step = .01, ticks = FALSE)
)

renderPlot({
  bin.knn(formula = grade ~ famincome, data = dt.org,
    n.group = input$n_group, min.bucket = input$min_pop)
})
```

**Optimal Binning Based on Decision Tree: `bin.rpart`**
```{r,eval=TRUE}
rpart(formula = grade ~ famincome, data = dt.org,
  control = rpart.control(cp = 0.01, minbucket = .05 * nrow(dt.org)))

bin1 <- bin.rpart(formula = grade ~ famincome, data = dt.org,
  rcontrol = rpart.control(cp = 0.01, minbucket = .05 * nrow(dt.org)))
data.frame(value = dt.org$famincome, bin = bin1$bins) %>% head
```
</ul>


## Exploratory Data Analysis
<ul class = "incremental">
**Level Statistics (Frequence, Rate, and Information Values): `level.stat`**

- Information Value (IV) is used to evaluate how strong a predcitor can differentiate the good/bad outcomes
- If IV < 0.02: the predictor has little predicting power

```{r}
stat <- level.stat(dt, y = 'grade')
stat[1:17, c(1:5, 16:17)]
```

**Visualizing Level Statistics: `ggstat`**
```{r,fig.height=18,fig.width=8}
stat$Variable.IV <- factor(stat$Variable.IV, levels = unique(stat$Variable.IV))
ggstat(data = stat, var = 'Variable.IV', ncol = 3)
```

**Correlation between Independent Variables: `ggcorr`**
```{r}
col.numeric <- sapply(dt, is.numeric) %>% which %>% names
cor.mat <- cor(dt[, col.numeric])
corrplot::corrplot(cor.mat)
ggcorr(cor.mat, lower = TRUE, var.position = 'diagonal', psize = 2,
  add.legend = F)
```
</ul>

## Modeling: Preparation
<ul class = "incremental">
**Spliting Data into Training and Test Data sets**
```{r}
levels(dt$grade) <- list(Fail = 0, Pass = 1)  
set.seed(123456)
ind.train <- createDataPartition(dt$grade, p = .75, list = FALSE)
dt.train <- dt[ind.train, ]
dt.test <- dt[-ind.train, ]
row.names(dt.train) <- NULL
row.names(dt.test) <- NULL
dim(dt.train)
dim(dt.test)
```


**Parallel Training Function**
```{r}
train.par <- function(data = dt.train, method, tuneLength = 10, ...) {
  set.seed(123456)
  cl <- makeCluster(3)
  registerDoSNOW(cl)
  fit <- train(grade ~ .,
    data = data,
    method = method,
    metric = 'ROC', 
    tuneLength = tuneLength,
    trControl = trainControl(
      method = "repeatedcv",
      number = 10,
      repeats = 10,
      classProbs = TRUE,
      summaryFunction = twoClassSummary),
    ...)
  stopCluster(cl)
  return(fit)
}
```
</ul>

## Modeling: Key Factors Identification
<ul class = "incremental">
```{r,include=FALSE}
load('Data/models_ROC.123456.Rdata')
```
**Elastic-Net: A Combination of Ridge and Lasso**
$$
\min_{\beta_0,\beta} \frac{1}{N} \sum_{i=1}^{N} w_i l(y_i,\beta_0+\beta^T x_i) + \lambda\left[(1-\alpha)||\beta||_2^2/2 + \alpha ||\beta||_1\right],
$$

- Modeling with Ordinal Variables as Numeric Data
```{r,eval=FALSE}
fit.el <- train.par(method = 'glmnet')
```

```{r}
fit.el$bestTune

# Best Model Coefficients
coef.el <- coef(fit.el$finalModel, s = fit.el$bestTune$lambda)
coef.el
```

- Convert Unselected Ordinal Variables to Categorical Data
```{r}
x.select <- row.names(coef.el)[(coef.el[, 1] != 0)]
x.numeric <- sapply(dt.train, is.numeric) %>% which %>% names
x.o2c <- setdiff(x.numeric, x.select)
dt.o2c <- dt.train
dt.o2c[x.o2c] <- lapply(dt.o2c[x.o2c], as.factor)
str(dt.o2c)
```

```{r,eval=FALSE}
fit.el.o2c <- train.par(data = dt.o2c, method = 'glmnet')
```

```{r}
coef.el.o2c <- coef(fit.el.o2c$finalModel, s = fit.el.o2c$bestTune$lambda)
coef.el.o2c
```

- Build Logistic Model with The Selected Variables
```{r}
x.select.o2c <- row.names(coef.el.o2c)[(coef.el.o2c[, 1] != 0)]
x.mat <- model.matrix(~., data = select(dt.o2c, -grade))[, -1]
dt.select <- data.frame(x.mat[, x.select.o2c[-1]], grade = dt.o2c$grade)
head(dt.select)

lg <- glm(grade ~ ., data = dt.select, family = binomial(link='logit'))
summary(lg)

car::vif(lg)  ## Check Multicollinearity
```
</ul>


## Modeling: Prediction
**Predictive Models: PLS, RF, GBM, and SVM**
```{r,eval=FALSE}
fit.pls <- train.par(method = 'pls')  # Partial Least Squares
fit.rf <- train.par(method = 'rf')  # Random Forest
fit.gbm <- train.par(method = 'gbm')  # Gradient Boosting Machine
fit.svm <- train.par(method = 'svmRadial')  # Support Vector Machine
```


##Model Performance
<ul class = "incremental">
**ROC of Cross-Validation**
```{r}
roc.cv <- resamples(list(
  EL = fit.el,
  PLS = fit.pls,
  RF = fit.rf,
  GBM = fit.gbm,
  SVM = fit.svm))
summary(roc.cv)
bwplot(roc.cv)

# Statistical Test of Model Differences 
roc.cv.dif <- diff(roc.cv)
summary(roc.cv.dif)
bwplot(roc.cv.dif)
```


**ROC of Test Data**
```{r}
models <- c('fit.el', 'fit.pls', 'fit.rf', 'fit.gbm', 'fit.svm')
roc.cal <- function(model) {
  grade.pred <-  predict(get(model), newdata = dt.test, type = 'prob')[, 2]
  value <- roc(dt.test$grade, grade.pred)
  df <- data.frame(
    Model = toupper(gsub('fit.', '', model)),
    ROC = as.numeric(value$auc),
    TPR = value$sensitivities,
    FPR = 1 - value$specificities) %>%
    arrange(Model, ROC, FPR, TPR) %>%
    transform(Model.ROC = paste(Model, ':', round(ROC, 3)))
}

roc.test <- lapply(models, roc.cal) %>%
  do.call(rbind, .)

ggplot(roc.test, aes(x = FPR, y = TPR, color = Model.ROC)) +
  geom_line(size = 2) +
  theme_bw()
```


**Accuracy of Test Data**
```{r}
acc.test <- lapply(models, function(x) {
  pred <- predict(get(x), dt.test)
  postResample(pred, dt.test$grade)
})

acc.test <- do.call(rbind, acc.test) %>%
  data.frame(Model = toupper(gsub('fit.', '', models)), .) %>%
  arrange(desc(Kappa))

acc.test
```
</ul>

## Conclusion
<ul class = "incremental">
- Key Factors: `r x.select[-1]`
```{r}
summary(lg)$coefficients
```

- Predictive Models Ranking: 
```{r}
result.cv <- apply(roc.cv$values[, -1], 2, median) %>% data.frame
result.groups <- strsplit(row.names(result.cv), '~') %>% do.call(rbind, .) 

results <- data.frame(result.groups, result.cv) %>% 
  dcast(X1 ~ X2) %>% 
  dplyr::rename(Model = X1, ROC.CV = ROC, Sens.CV = Sens, Spec.CV = Spec) %>%
  left_join(unique(select(roc.test, Model, ROC.Test = ROC)), by = 'Model') %>%
  left_join(select(acc.test, Model, Accuracy.Test = Accuracy, Kappa.Test = Kappa)) %>%
  arrange(desc(ROC.CV))
results
```
</ul>

```{r,include=FALSE,eval=FALSE}
save(fit.el, fit.el.o2c, fit.pls, fit.rf, fit.gbm, fit.svm, 
  file = 'Data/models_ROC.123456.Rdata')
```

## Reference:
<ul class = "incremental">
* streamlineR package information: https://github.com/JianhuaHuang/streamlineR 
* Information Value: http://multithreaded.stitchfix.com/blog/2015/08/13/weight-of-evidence/ 
* shinyapp: https://jianhua.shinyapps.io/powerplants/ 
</ul>
